{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "N = 77\n",
    "ch = 256\n",
    "H = 23\n",
    "W = 41\n",
    "\n",
    "h = np.random.randn(N, ch, H, W).astype(np.float32)\n",
    "c = np.random.randint(low=0, high=10, size=(N,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10_models import Cifar10Discriminator\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "d = Cifar10Discriminator()\n",
    "\n",
    "batchsize = 94\n",
    "\n",
    "x_real = np.random.randn(batchsize, 3, 32, 32)\n",
    "x_fake = np.random.randn(batchsize, 3, 32, 32)\n",
    "\n",
    "x_real_t = torch.from_numpy(x_real).float()\n",
    "x_fake_t = torch.from_numpy(x_fake).float()\n",
    "\n",
    "eps = torch.rand(batchsize, 1, 1, 1)\n",
    "\n",
    "x_mid = eps * x_real_t + (1 - eps) * x_fake_t\n",
    "x_mid.detach()\n",
    "x_mid.requires_grad = True\n",
    "\n",
    "y_mid = d(x_mid)\n",
    "\n",
    "device='cpu'\n",
    "grad_outputs = torch.ones_like(y).to(device)\n",
    "\n",
    "grads = torch.autograd.grad(\n",
    "    outputs=y_mid, \n",
    "    inputs=x_mid,\n",
    "    grad_outputs=grad_outputs,\n",
    "    create_graph=True, retain_graph=True, only_inputs=True\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.7379e-04,  6.0373e-03, -8.1126e-03,  ..., -2.3483e-03,\n",
       "           -6.2511e-04, -6.2645e-03],\n",
       "          [-3.9958e-03, -1.9357e-03, -1.1247e-02,  ..., -1.0580e-02,\n",
       "           -6.4290e-03, -4.9055e-03],\n",
       "          [ 5.5178e-04, -3.8025e-03, -6.8274e-03,  ..., -4.1134e-03,\n",
       "           -2.7571e-03, -5.3128e-03],\n",
       "          ...,\n",
       "          [ 8.0973e-04,  2.1361e-03, -4.8110e-03,  ..., -1.3275e-03,\n",
       "           -4.0379e-03, -2.4637e-03],\n",
       "          [ 3.9174e-03,  3.7620e-03, -4.1719e-03,  ..., -1.3490e-03,\n",
       "           -6.3068e-03, -3.9776e-03],\n",
       "          [-1.6741e-03, -1.9754e-03, -6.7247e-03,  ..., -3.2827e-03,\n",
       "           -3.4770e-03, -4.7825e-03]],\n",
       "\n",
       "         [[ 1.7558e-04,  5.1839e-03,  1.0983e-03,  ...,  2.0585e-03,\n",
       "           -1.2118e-03, -3.0081e-03],\n",
       "          [ 2.6435e-03, -1.3379e-03, -2.2619e-03,  ...,  4.3776e-03,\n",
       "            4.4049e-03,  2.7772e-03],\n",
       "          [ 7.1664e-03,  5.3255e-03,  3.1045e-03,  ...,  1.5984e-03,\n",
       "            5.0585e-03,  6.4077e-03],\n",
       "          ...,\n",
       "          [ 4.7161e-03,  3.6427e-03,  1.7326e-03,  ...,  5.5210e-03,\n",
       "           -2.0099e-03,  6.7575e-03],\n",
       "          [-1.2278e-04,  4.4491e-03,  2.1193e-03,  ..., -2.7296e-03,\n",
       "            1.8285e-03,  3.1728e-03],\n",
       "          [ 1.8898e-03,  4.7922e-04, -1.0771e-03,  ..., -1.6596e-03,\n",
       "           -3.1858e-03, -2.5595e-03]],\n",
       "\n",
       "         [[-2.4050e-03, -1.1610e-03,  3.6005e-03,  ...,  1.4834e-03,\n",
       "            5.0498e-03,  2.4534e-03],\n",
       "          [-2.1953e-03, -8.7475e-03, -2.3078e-04,  ..., -2.4586e-03,\n",
       "           -1.0853e-03, -7.2781e-03],\n",
       "          [-5.7573e-03, -1.9241e-03, -8.8037e-03,  ...,  9.2376e-04,\n",
       "           -1.1273e-03, -5.1888e-03],\n",
       "          ...,\n",
       "          [-3.5812e-03,  1.5136e-03,  1.4926e-03,  ...,  1.3108e-02,\n",
       "            7.7539e-06,  2.1532e-03],\n",
       "          [-6.4528e-03, -3.5342e-03,  2.1756e-03,  ..., -7.0749e-03,\n",
       "           -1.1043e-03,  1.1677e-04],\n",
       "          [-4.0943e-03, -3.1688e-03, -4.4856e-03,  ..., -2.7599e-03,\n",
       "            1.6612e-03, -1.3315e-03]]],\n",
       "\n",
       "\n",
       "        [[[-3.7065e-05, -3.9456e-03, -9.3000e-03,  ..., -8.2867e-03,\n",
       "           -2.0103e-03, -3.8187e-03],\n",
       "          [ 1.6675e-03,  1.9904e-03, -3.2261e-03,  ..., -1.1027e-02,\n",
       "           -5.9325e-03, -3.8291e-03],\n",
       "          [ 4.9919e-04, -8.9614e-04, -1.2612e-02,  ..., -6.4515e-03,\n",
       "           -7.1644e-04, -3.7435e-03],\n",
       "          ...,\n",
       "          [-1.3895e-03, -5.5756e-03, -2.5306e-03,  ..., -6.7053e-03,\n",
       "           -5.6173e-05,  8.0388e-04],\n",
       "          [-3.9987e-03, -1.0008e-03, -7.6358e-03,  ...,  3.5149e-03,\n",
       "           -8.8001e-04, -2.3972e-03],\n",
       "          [-6.4641e-03, -3.4682e-03, -8.3234e-03,  ...,  9.8245e-04,\n",
       "           -1.3368e-03, -1.7936e-03]],\n",
       "\n",
       "         [[-2.6137e-05,  9.8808e-03,  3.0044e-03,  ..., -4.0881e-04,\n",
       "            3.3819e-03,  5.3909e-04],\n",
       "          [-2.7190e-03, -5.2409e-03,  5.4671e-03,  ..., -1.6373e-03,\n",
       "            2.5525e-03,  3.8966e-03],\n",
       "          [-2.1521e-03,  3.6460e-03, -1.1084e-03,  ...,  7.2166e-04,\n",
       "           -2.4317e-03, -5.6539e-04],\n",
       "          ...,\n",
       "          [ 5.1234e-04,  9.8083e-03,  2.8403e-03,  ...,  8.3782e-03,\n",
       "           -3.5674e-04,  2.1822e-04],\n",
       "          [ 3.2481e-03,  2.1381e-03,  6.0619e-03,  ..., -4.0731e-03,\n",
       "            2.7881e-03,  5.9740e-03],\n",
       "          [ 3.1475e-03,  8.8588e-03,  1.2402e-03,  ..., -4.4496e-03,\n",
       "           -8.1939e-04, -7.3519e-04]],\n",
       "\n",
       "         [[-8.1148e-03, -2.5076e-03, -4.5811e-03,  ..., -1.4581e-04,\n",
       "            7.3991e-04, -1.1368e-03],\n",
       "          [-2.2727e-03,  1.2795e-04, -8.8631e-03,  ..., -6.4572e-05,\n",
       "           -1.9949e-03, -4.8101e-05],\n",
       "          [-9.3478e-03, -1.6089e-02,  4.5059e-03,  ..., -2.2140e-03,\n",
       "            3.7083e-03, -1.0938e-03],\n",
       "          ...,\n",
       "          [-8.4626e-04, -1.3534e-02, -3.3949e-03,  ..., -8.1984e-03,\n",
       "           -2.9484e-03, -2.6579e-04],\n",
       "          [ 8.7079e-04, -1.5616e-02,  5.2586e-04,  ...,  3.9514e-03,\n",
       "            6.0711e-03, -2.8836e-03],\n",
       "          [-1.2086e-02, -2.8857e-03, -6.0060e-04,  ..., -5.7731e-03,\n",
       "           -3.5860e-04,  2.7996e-03]]],\n",
       "\n",
       "\n",
       "        [[[-7.8017e-03, -8.7770e-03, -5.0234e-03,  ..., -8.2537e-03,\n",
       "            1.4664e-03, -4.1949e-03],\n",
       "          [ 3.5034e-03, -6.9463e-03,  1.5900e-03,  ...,  7.2624e-03,\n",
       "            4.6807e-03, -1.3211e-03],\n",
       "          [-4.4930e-03, -5.6356e-03,  1.9647e-03,  ..., -3.1710e-03,\n",
       "           -7.8744e-03, -4.3597e-03],\n",
       "          ...,\n",
       "          [-6.9457e-03, -3.0677e-04, -1.7461e-04,  ..., -8.0587e-03,\n",
       "            6.2987e-03,  6.4275e-03],\n",
       "          [-5.8877e-04, -4.8154e-03, -2.8704e-03,  ..., -2.8954e-03,\n",
       "            1.2644e-03,  5.3789e-03],\n",
       "          [ 2.1756e-04,  2.6808e-04, -7.5321e-03,  ..., -1.9309e-03,\n",
       "            2.7524e-03,  4.2055e-03]],\n",
       "\n",
       "         [[ 1.3034e-03,  2.9448e-03,  4.6381e-03,  ..., -2.3558e-03,\n",
       "            2.3517e-05,  1.4759e-03],\n",
       "          [-4.8212e-03,  2.5858e-03,  8.2735e-03,  ...,  7.4191e-03,\n",
       "            7.1344e-03,  2.9227e-03],\n",
       "          [-8.4232e-04, -2.9470e-03,  7.7036e-03,  ...,  9.6468e-04,\n",
       "            5.3042e-03,  3.2719e-03],\n",
       "          ...,\n",
       "          [ 1.0187e-03,  6.5112e-03, -5.3585e-03,  ..., -6.2679e-03,\n",
       "           -5.2621e-03, -5.4354e-03],\n",
       "          [ 6.0253e-03,  8.7854e-03, -1.1201e-03,  ..., -5.9127e-03,\n",
       "           -4.4635e-03,  2.1331e-03],\n",
       "          [ 2.0637e-03,  6.8891e-03,  4.2010e-03,  ..., -5.6739e-03,\n",
       "           -4.0777e-03, -1.3429e-03]],\n",
       "\n",
       "         [[-6.8971e-03, -1.4664e-03, -1.6770e-02,  ...,  7.9386e-04,\n",
       "           -6.1107e-03, -4.9938e-04],\n",
       "          [-8.0028e-03, -1.0544e-02, -1.2361e-02,  ..., -1.1226e-02,\n",
       "            2.2196e-03, -3.1942e-04],\n",
       "          [-1.0524e-02, -5.5631e-03, -1.6342e-02,  ..., -8.0748e-03,\n",
       "           -3.1080e-03, -3.3644e-03],\n",
       "          ...,\n",
       "          [-7.4905e-03, -5.1258e-03, -5.7579e-03,  ..., -3.1725e-03,\n",
       "           -6.5873e-03, -2.0749e-03],\n",
       "          [ 4.3753e-03, -1.2845e-02, -2.1472e-03,  ...,  4.3606e-04,\n",
       "            1.1507e-03, -1.2671e-03],\n",
       "          [-1.6070e-03, -2.6592e-04, -3.5288e-03,  ..., -3.2681e-03,\n",
       "            4.6159e-03, -1.8736e-03]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-2.3570e-04, -1.3762e-03, -3.4693e-03,  ..., -6.9438e-03,\n",
       "           -6.2725e-03, -1.5059e-03],\n",
       "          [-3.5671e-03, -9.9586e-03, -5.7425e-03,  ..., -4.5296e-03,\n",
       "           -7.8566e-03, -3.3975e-03],\n",
       "          [ 1.5316e-03,  4.8527e-03, -5.1034e-03,  ..., -1.6702e-03,\n",
       "           -8.8284e-03, -2.2435e-03],\n",
       "          ...,\n",
       "          [-1.8937e-03, -1.7446e-03,  1.4869e-03,  ..., -4.6084e-03,\n",
       "           -7.0646e-03, -4.8504e-03],\n",
       "          [ 1.7717e-03,  8.4294e-04, -2.5673e-03,  ...,  6.1592e-03,\n",
       "            1.8768e-03, -9.3466e-04],\n",
       "          [ 9.5840e-04,  2.2223e-03, -2.4803e-03,  ..., -5.9483e-03,\n",
       "           -4.8033e-03, -1.5604e-03]],\n",
       "\n",
       "         [[ 2.7831e-03,  2.2597e-03,  1.2116e-03,  ..., -7.7966e-04,\n",
       "           -2.2059e-03, -3.0370e-03],\n",
       "          [-2.4889e-03,  1.0963e-02, -4.1409e-03,  ..., -4.6632e-04,\n",
       "            5.3476e-03,  1.5036e-03],\n",
       "          [-2.6213e-03,  2.5319e-03, -2.8747e-03,  ..., -1.2583e-03,\n",
       "            1.8522e-03,  4.3767e-03],\n",
       "          ...,\n",
       "          [ 1.7506e-03,  8.0577e-03,  7.4602e-03,  ..., -6.3183e-03,\n",
       "            7.2039e-03, -1.1265e-03],\n",
       "          [ 7.1523e-03,  9.3399e-03, -1.0715e-03,  ...,  4.3092e-04,\n",
       "           -1.0327e-02, -9.7599e-04],\n",
       "          [ 5.3529e-03,  5.8883e-03,  5.2288e-03,  ..., -1.1068e-02,\n",
       "           -1.8805e-03,  1.2028e-03]],\n",
       "\n",
       "         [[-8.3034e-03, -3.6509e-03, -3.5550e-03,  ...,  2.1217e-04,\n",
       "           -1.1420e-03, -3.4163e-03],\n",
       "          [-4.6559e-03, -9.0138e-03, -9.4829e-03,  ..., -2.1112e-03,\n",
       "           -7.1276e-03, -6.7952e-03],\n",
       "          [-4.6427e-03, -5.7985e-03, -1.6024e-02,  ..., -6.9521e-03,\n",
       "           -3.6374e-03, -5.8316e-03],\n",
       "          ...,\n",
       "          [-9.1307e-03,  8.5424e-04,  1.5298e-04,  ...,  1.7287e-03,\n",
       "            3.6482e-03, -3.7320e-04],\n",
       "          [-2.6753e-03, -2.0624e-04, -6.1807e-03,  ..., -6.1047e-04,\n",
       "            3.2413e-03,  3.8666e-03],\n",
       "          [-3.4783e-03, -1.3530e-03, -1.0378e-03,  ...,  2.3629e-03,\n",
       "            2.6182e-03,  3.1249e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 3.1879e-03,  1.3742e-03, -5.1085e-03,  ..., -3.5060e-03,\n",
       "           -5.9844e-03, -1.8340e-03],\n",
       "          [-1.1523e-03,  7.6562e-04, -2.5324e-03,  ..., -7.5923e-03,\n",
       "           -1.3722e-02, -6.4081e-03],\n",
       "          [ 3.2510e-03, -1.7586e-03, -1.3316e-03,  ..., -4.8201e-03,\n",
       "           -4.5756e-03, -8.2290e-03],\n",
       "          ...,\n",
       "          [-3.5149e-03, -9.2636e-03, -1.9001e-02,  ...,  5.4665e-05,\n",
       "            3.1660e-03,  4.0649e-03],\n",
       "          [ 1.0983e-03, -2.5734e-03, -9.7939e-03,  ..., -3.0360e-03,\n",
       "            5.9675e-03,  5.3711e-03],\n",
       "          [-3.9550e-03, -5.9982e-03, -6.2806e-03,  ..., -7.8530e-03,\n",
       "           -2.4822e-04,  1.8610e-03]],\n",
       "\n",
       "         [[ 1.4372e-03,  3.4185e-03,  2.0847e-04,  ..., -5.7651e-03,\n",
       "            1.6462e-03, -2.8961e-03],\n",
       "          [-2.9670e-05, -2.0009e-03, -4.9911e-03,  ...,  1.0441e-02,\n",
       "            6.0224e-03,  4.1593e-03],\n",
       "          [-5.2110e-03, -9.8560e-04,  2.6032e-03,  ...,  4.0864e-03,\n",
       "            7.7697e-03,  3.7700e-03],\n",
       "          ...,\n",
       "          [-2.3180e-04,  1.3249e-02,  4.2140e-03,  ..., -5.9670e-03,\n",
       "           -1.0261e-03,  3.9653e-03],\n",
       "          [-2.6354e-04,  6.0270e-03,  3.1378e-03,  ..., -1.3623e-02,\n",
       "           -7.9407e-03, -1.1534e-03],\n",
       "          [ 5.0464e-04,  2.4698e-03,  7.0476e-03,  ..., -4.2509e-03,\n",
       "           -3.4966e-03,  6.5560e-04]],\n",
       "\n",
       "         [[-4.5644e-03, -1.1747e-03, -4.8847e-03,  ...,  2.3832e-03,\n",
       "            2.6938e-03,  1.2576e-03],\n",
       "          [-1.1859e-02, -4.2078e-03, -8.6077e-04,  ..., -3.4023e-03,\n",
       "           -2.2340e-03,  1.4625e-03],\n",
       "          [-4.1375e-03,  1.0515e-03, -4.8156e-03,  ...,  1.1581e-03,\n",
       "            2.1913e-03, -1.8117e-03],\n",
       "          ...,\n",
       "          [-8.3746e-04, -1.0101e-02, -5.5454e-03,  ...,  4.7926e-03,\n",
       "           -2.2838e-03, -5.5507e-03],\n",
       "          [ 3.7056e-03, -3.9902e-03, -1.0977e-02,  ...,  2.5610e-03,\n",
       "           -5.1128e-03,  6.9845e-03],\n",
       "          [-4.4321e-03, -9.2673e-03, -6.1104e-03,  ..., -1.4297e-03,\n",
       "            5.2449e-03,  4.5057e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1578e-03,  3.7300e-03, -3.0694e-03,  ..., -9.0172e-04,\n",
       "           -4.6968e-03, -5.7897e-03],\n",
       "          [ 1.5704e-03, -5.0077e-03, -1.5798e-02,  ..., -7.1729e-03,\n",
       "           -9.7398e-03, -1.0044e-02],\n",
       "          [-3.6245e-03, -1.8185e-03, -9.0049e-03,  ..., -2.5416e-03,\n",
       "           -1.8104e-03,  2.0797e-03],\n",
       "          ...,\n",
       "          [-6.3192e-04, -7.0161e-03, -1.0743e-02,  ..., -1.6037e-03,\n",
       "            7.2170e-03,  2.4292e-04],\n",
       "          [-1.0672e-03,  1.8793e-04, -1.1026e-02,  ..., -5.4906e-03,\n",
       "           -3.9687e-04,  5.1589e-03],\n",
       "          [-8.3514e-03, -1.3241e-02, -1.1571e-02,  ..., -1.0904e-02,\n",
       "            1.2745e-03,  5.0630e-03]],\n",
       "\n",
       "         [[ 1.3634e-03,  6.2611e-03,  2.9368e-03,  ...,  1.0341e-03,\n",
       "            1.3202e-03, -2.9786e-03],\n",
       "          [ 5.3378e-04,  4.6824e-03, -2.3374e-03,  ...,  4.4526e-03,\n",
       "            3.3618e-04, -2.2481e-03],\n",
       "          [ 1.9373e-03, -3.2696e-03,  4.9313e-03,  ..., -3.1586e-03,\n",
       "           -1.2457e-03,  4.1471e-03],\n",
       "          ...,\n",
       "          [-3.2576e-03,  1.2500e-02,  4.1784e-03,  ...,  5.4797e-03,\n",
       "           -3.4889e-03, -5.6615e-03],\n",
       "          [ 1.4640e-03,  7.4921e-03,  6.0974e-03,  ...,  1.6171e-03,\n",
       "            5.0056e-04,  7.2711e-04],\n",
       "          [ 5.1673e-03,  5.8178e-03,  9.0524e-03,  ..., -1.9849e-03,\n",
       "           -1.2525e-03, -3.4168e-03]],\n",
       "\n",
       "         [[ 1.2917e-03, -6.4168e-03, -6.3264e-03,  ...,  1.8047e-03,\n",
       "            7.4282e-04, -4.4308e-03],\n",
       "          [-8.7709e-03, -3.7182e-03, -9.5342e-03,  ..., -6.1590e-03,\n",
       "           -8.1325e-03, -1.8646e-03],\n",
       "          [-3.1709e-03, -7.3761e-03, -7.2312e-03,  ..., -5.4648e-03,\n",
       "            3.8905e-04, -8.2241e-03],\n",
       "          ...,\n",
       "          [-6.1307e-03, -8.0965e-03, -1.5528e-02,  ..., -6.2920e-04,\n",
       "            6.0656e-04,  1.3633e-03],\n",
       "          [-6.6123e-03, -6.2393e-03, -8.4743e-03,  ...,  1.4051e-03,\n",
       "           -2.1219e-03, -4.2701e-03],\n",
       "          [-5.6219e-03, -1.0128e-02, -2.2951e-03,  ...,  8.2498e-03,\n",
       "           -1.2029e-03,  6.8256e-04]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 1, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [4401396616, 4401393952]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [4401396616, 4401393952]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 1, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [4401396616, 4401393952]}]}\n"
     ]
    }
   ],
   "source": [
    "sd = optim.state_dict()print(sd)\n",
    "\n",
    "optim_2 = torch.optim.Adam(model.parameters(), lr = .001)\n",
    "print(optim_2.state_dict())\n",
    "\n",
    "optim_2.load_state_dict(sd)\n",
    "print(optim_2.state_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=DEFAULT_SN_GAN_DATA_PATH, \n",
    "    train=True,\n",
    "    download=True, \n",
    "    # transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size=64,\n",
    "    num_workers=1,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "image = trainset[n][0]\n",
    "\n",
    "arr = torchvision.transforms.ToTensor()(image)\n",
    "\n",
    "arr = arr*2 - 1\n",
    "print(arr.shape)\n",
    "\n",
    "img = torchvision.transforms.ToPILImage()(arr)\n",
    "\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConditionalBatchNorm2d(nn.Module):\n",
    "    # Thanks to https://github.com/Kaixhin for this layer\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.bn = nn.BatchNorm2d(num_features, affine=False)\n",
    "        self.embed = nn.Embedding(num_classes, num_features * 2)\n",
    "        self.embed.weight.data[:, :num_features] = 1  \n",
    "        self.embed.weight.data[:, num_features:] = 0  \n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.bn(x)\n",
    "        gamma, beta = self.embed(y).chunk(2, 1)\n",
    "        out = gamma.view(-1, self.num_features, 1, 1) * out + beta.view(-1, self.num_features, 1, 1)\n",
    "        return out\n",
    "    \n",
    "ConditionalBatchNorm2d(128, 10).embed.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p shape:  torch.Size([94, 128])\n",
      "label weight shape: torch.Size([94, 128])\n",
      "label_weights * p shape: torch.Size([94, 128])\n",
      "torch.Size([94, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-18.4368],\n",
       "        [-17.7502],\n",
       "        [-18.1937],\n",
       "        [-18.2506],\n",
       "        [-17.7299],\n",
       "        [-17.4220],\n",
       "        [-17.7976],\n",
       "        [-17.4032],\n",
       "        [-18.1591],\n",
       "        [-17.5930],\n",
       "        [-17.7073],\n",
       "        [-17.3667],\n",
       "        [-17.6906],\n",
       "        [-18.0051],\n",
       "        [-18.2365],\n",
       "        [-17.4930],\n",
       "        [-18.0018],\n",
       "        [-17.9581],\n",
       "        [-17.9253],\n",
       "        [-17.1292],\n",
       "        [-17.3356],\n",
       "        [-17.7500],\n",
       "        [-17.6907],\n",
       "        [-18.5198],\n",
       "        [-17.4648],\n",
       "        [-17.8622],\n",
       "        [-17.9219],\n",
       "        [-18.0552],\n",
       "        [-17.3677],\n",
       "        [-18.0826],\n",
       "        [-17.3437],\n",
       "        [-17.3026],\n",
       "        [-18.3996],\n",
       "        [-17.8657],\n",
       "        [-17.5924],\n",
       "        [-17.0631],\n",
       "        [-17.8615],\n",
       "        [-17.8787],\n",
       "        [-17.6510],\n",
       "        [-17.2374],\n",
       "        [-17.5856],\n",
       "        [-18.1056],\n",
       "        [-17.9741],\n",
       "        [-17.7555],\n",
       "        [-17.0572],\n",
       "        [-17.3080],\n",
       "        [-17.3251],\n",
       "        [-17.7208],\n",
       "        [-17.6329],\n",
       "        [-17.8323],\n",
       "        [-17.8338],\n",
       "        [-17.4566],\n",
       "        [-17.2865],\n",
       "        [-18.3213],\n",
       "        [-18.3984],\n",
       "        [-18.2100],\n",
       "        [-18.0489],\n",
       "        [-17.6685],\n",
       "        [-17.4856],\n",
       "        [-17.8841],\n",
       "        [-17.9546],\n",
       "        [-18.2200],\n",
       "        [-17.8627],\n",
       "        [-17.9270],\n",
       "        [-18.3554],\n",
       "        [-17.6095],\n",
       "        [-17.5101],\n",
       "        [-18.2542],\n",
       "        [-17.6090],\n",
       "        [-18.7554],\n",
       "        [-17.7120],\n",
       "        [-17.6799],\n",
       "        [-18.0085],\n",
       "        [-17.7826],\n",
       "        [-17.6774],\n",
       "        [-17.5456],\n",
       "        [-17.9821],\n",
       "        [-17.9756],\n",
       "        [-17.2446],\n",
       "        [-18.0225],\n",
       "        [-17.9970],\n",
       "        [-18.0242],\n",
       "        [-17.7723],\n",
       "        [-17.7110],\n",
       "        [-17.5816],\n",
       "        [-17.3017],\n",
       "        [-17.4619],\n",
       "        [-17.6448],\n",
       "        [-17.5778],\n",
       "        [-17.6738],\n",
       "        [-17.7610],\n",
       "        [-17.9716],\n",
       "        [-17.9107],\n",
       "        [-17.4495]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cifar10_models import Cifar10Discriminator\n",
    "import torch \n",
    "\n",
    "\n",
    "dis = Cifar10Discriminator(n_classes=5)\n",
    "\n",
    "im = torch.rand(94, 3, 32, 32) * 2 - 1\n",
    "labels = torch.ones((94, ), dtype=torch.long)\n",
    "\n",
    "dis(im, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
