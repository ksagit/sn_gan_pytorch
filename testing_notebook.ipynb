{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nscheduler = torch.optim.lr_scheduler.LambdaLR(optim, lambda epoch: 1 - epoch/max_epochs, -1)\\n\\nfor _ in range(max_epochs):\\n    for param_group in optim.param_groups:\\n        print(param_group['lr'])\\n    scheduler.step()\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch \n",
    "\n",
    "model = nn.Linear(100, 10)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 1)\n",
    "max_epochs = 5000\n",
    "\n",
    "\"\"\"\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lambda epoch: 1 - epoch/max_epochs, -1)\n",
    "\n",
    "for _ in range(max_epochs):\n",
    "    for param_group in optim.param_groups:\n",
    "        print(param_group['lr'])\n",
    "    scheduler.step()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr = 0\n",
    "def foo():\n",
    "    global ctr\n",
    "    ctr += 1\n",
    "    return ctr\n",
    "\n",
    "print(foo()\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 1, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [4401396616, 4401393952]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [4401396616, 4401393952]}]}\n",
      "{'state': {}, 'param_groups': [{'lr': 1, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [4401396616, 4401393952]}]}\n"
     ]
    }
   ],
   "source": [
    "sd = optim.state_dict()\n",
    "print(sd)\n",
    "\n",
    "optim_2 = torch.optim.Adam(model.parameters(), lr = .001)\n",
    "print(optim_2.state_dict())\n",
    "\n",
    "optim_2.load_state_dict(sd)\n",
    "print(optim_2.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=DEFAULT_SN_GAN_DATA_PATH, \n",
    "    train=True,\n",
    "    download=True, \n",
    "    # transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size=64,\n",
    "    num_workers=1,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "image = trainset[n][0]\n",
    "\n",
    "arr = torchvision.transforms.ToTensor()(image)\n",
    "\n",
    "arr = arr*2 - 1\n",
    "print(arr.shape)\n",
    "\n",
    "img = torchvision.transforms.ToPILImage()(arr)\n",
    "\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConditionalBatchNorm2d(nn.Module):\n",
    "    # Thanks to https://github.com/Kaixhin for this layer\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.bn = nn.BatchNorm2d(num_features, affine=False)\n",
    "        self.embed = nn.Embedding(num_classes, num_features * 2)\n",
    "        self.embed.weight.data[:, :num_features] = 1  \n",
    "        self.embed.weight.data[:, num_features:] = 0  \n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = self.bn(x)\n",
    "        gamma, beta = self.embed(y).chunk(2, 1)\n",
    "        out = gamma.view(-1, self.num_features, 1, 1) * out + beta.view(-1, self.num_features, 1, 1)\n",
    "        return out\n",
    "    \n",
    "ConditionalBatchNorm2d(128, 10).embed.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p shape:  torch.Size([94, 128])\n",
      "label weight shape: torch.Size([94, 128])\n",
      "label_weights * p shape: torch.Size([94, 128])\n",
      "torch.Size([94, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-18.4368],\n",
       "        [-17.7502],\n",
       "        [-18.1937],\n",
       "        [-18.2506],\n",
       "        [-17.7299],\n",
       "        [-17.4220],\n",
       "        [-17.7976],\n",
       "        [-17.4032],\n",
       "        [-18.1591],\n",
       "        [-17.5930],\n",
       "        [-17.7073],\n",
       "        [-17.3667],\n",
       "        [-17.6906],\n",
       "        [-18.0051],\n",
       "        [-18.2365],\n",
       "        [-17.4930],\n",
       "        [-18.0018],\n",
       "        [-17.9581],\n",
       "        [-17.9253],\n",
       "        [-17.1292],\n",
       "        [-17.3356],\n",
       "        [-17.7500],\n",
       "        [-17.6907],\n",
       "        [-18.5198],\n",
       "        [-17.4648],\n",
       "        [-17.8622],\n",
       "        [-17.9219],\n",
       "        [-18.0552],\n",
       "        [-17.3677],\n",
       "        [-18.0826],\n",
       "        [-17.3437],\n",
       "        [-17.3026],\n",
       "        [-18.3996],\n",
       "        [-17.8657],\n",
       "        [-17.5924],\n",
       "        [-17.0631],\n",
       "        [-17.8615],\n",
       "        [-17.8787],\n",
       "        [-17.6510],\n",
       "        [-17.2374],\n",
       "        [-17.5856],\n",
       "        [-18.1056],\n",
       "        [-17.9741],\n",
       "        [-17.7555],\n",
       "        [-17.0572],\n",
       "        [-17.3080],\n",
       "        [-17.3251],\n",
       "        [-17.7208],\n",
       "        [-17.6329],\n",
       "        [-17.8323],\n",
       "        [-17.8338],\n",
       "        [-17.4566],\n",
       "        [-17.2865],\n",
       "        [-18.3213],\n",
       "        [-18.3984],\n",
       "        [-18.2100],\n",
       "        [-18.0489],\n",
       "        [-17.6685],\n",
       "        [-17.4856],\n",
       "        [-17.8841],\n",
       "        [-17.9546],\n",
       "        [-18.2200],\n",
       "        [-17.8627],\n",
       "        [-17.9270],\n",
       "        [-18.3554],\n",
       "        [-17.6095],\n",
       "        [-17.5101],\n",
       "        [-18.2542],\n",
       "        [-17.6090],\n",
       "        [-18.7554],\n",
       "        [-17.7120],\n",
       "        [-17.6799],\n",
       "        [-18.0085],\n",
       "        [-17.7826],\n",
       "        [-17.6774],\n",
       "        [-17.5456],\n",
       "        [-17.9821],\n",
       "        [-17.9756],\n",
       "        [-17.2446],\n",
       "        [-18.0225],\n",
       "        [-17.9970],\n",
       "        [-18.0242],\n",
       "        [-17.7723],\n",
       "        [-17.7110],\n",
       "        [-17.5816],\n",
       "        [-17.3017],\n",
       "        [-17.4619],\n",
       "        [-17.6448],\n",
       "        [-17.5778],\n",
       "        [-17.6738],\n",
       "        [-17.7610],\n",
       "        [-17.9716],\n",
       "        [-17.9107],\n",
       "        [-17.4495]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cifar10_models import Cifar10Discriminator\n",
    "import torch \n",
    "\n",
    "\n",
    "dis = Cifar10Discriminator(n_classes=5)\n",
    "\n",
    "im = torch.rand(94, 3, 32, 32) * 2 - 1\n",
    "labels = torch.ones((94, ), dtype=torch.long)\n",
    "\n",
    "dis(im, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
